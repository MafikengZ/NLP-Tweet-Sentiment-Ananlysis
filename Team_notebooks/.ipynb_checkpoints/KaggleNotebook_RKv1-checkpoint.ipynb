{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddaacb69",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmsekgothe/load-shortfall-regression-predict-api/blob/master/KaggleNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    },
    "id": "6c7e849a"
   },
   "source": [
    "# Team 12 - Advanced Classification Predict\n",
    "\n",
    "Â© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction: \n",
    "---\n",
    "\n",
    "### Predict Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {
    "id": "05600c92"
   },
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {
    "id": "997462e2"
   },
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a772fd",
   "metadata": {},
   "source": [
    "In this section we import the necessary libraries needed for Data Analysis, Data Manipulation, Data Visualization and Model Building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    },
    "id": "475dbe93"
   },
   "outputs": [],
   "source": [
    "# libraries needed for Data Analysis and  Data Manipulation\n",
    "import numpy as np # used to evaluate arrays\n",
    "import pandas as pd # used to create and utilise tabular data ie Pandas DataFrame\n",
    "\n",
    "# libraries to be used for Data Visualization\n",
    "import matplotlib.pyplot as plt # used to visualize data\n",
    "import seaborn as sns # used to visualize data\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "import sklearn\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import requests\n",
    "from time import sleep\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Suppress cell warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822dafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {
    "id": "f22a6718"
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef4a15",
   "metadata": {
    "id": "d1ef4a15"
   },
   "source": [
    "- Loading of Test and Train datasets. \n",
    "- Concatenate the datasets to ensure Data Engineering is done only once (for convenience). \n",
    "- Dataframes will then be split later on when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    },
    "id": "fbbb6c18"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-388fce5a8935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_with_no_labels.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv') # load the data\n",
    "df_test = pd.read_csv('test_with_no_labels.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70c4c6",
   "metadata": {
    "id": "0d70c4c6"
   },
   "source": [
    "Perform basic analysis on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6884eb1",
   "metadata": {
    "id": "e6884eb1",
    "outputId": "40f402ad-7129-4394-d6ff-685148b0aeff"
   },
   "outputs": [],
   "source": [
    "# Basic Train Analysis\n",
    "\n",
    "df.shape # train DataFrame has 15 819 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8ceeb",
   "metadata": {
    "id": "7cf8ceeb",
    "outputId": "114d6eae-d08b-49d3-976f-770d94d19932"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d358def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts().plot(kind = 'bar')\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba224009",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(df['sentiment'], return_counts=True)\n",
    "unique_counts_dict = {'Unique Count':\n",
    "             {\n",
    "                 \"Class -1\": counts[0],\n",
    "                \"Class 0\": counts[1],\n",
    "              \"Class 1\": counts[2],\n",
    "              \"Class 2\": counts[3]\n",
    "              }\n",
    "             }\n",
    "unique_count = pd.DataFrame(data=unique_counts_dict)\n",
    "unique_count.sort_values(by='Unique Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c7743",
   "metadata": {},
   "source": [
    "Class Description:\n",
    "\n",
    "- 2 News: the tweet links to factual news about climate change\n",
    "- 1 Pro: the tweet supports the belief of man-made climate change\n",
    "- 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "- -1 Anti: the tweet does not believe in man-made climate change\n",
    "\n",
    "Note the imbalance here: there are over 8000 observations in class 1 and only 1296 observations in class -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Test Analysis\n",
    "\n",
    "df_test.shape # test DataFrame has 10 546 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd435fd",
   "metadata": {
    "id": "2bd435fd",
    "outputId": "1cd53952-ade3-4188-e465-80d344ca392f"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afe777",
   "metadata": {
    "id": "05afe777",
    "outputId": "45b56407-08f2-401d-ef96-790251cc013b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b7a88",
   "metadata": {
    "id": "730b7a88"
   },
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Data Preprocessing\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "#### Data Cleaning and Formatting\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34088e",
   "metadata": {},
   "source": [
    "Before we can do **Exploratory Data Analysis** (EDA) in section 4, we need to ensure that our data is in the correct format that can actually be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af824c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd5e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Better view of what's in the dataset\n",
    "for i, row in df.iterrows():\n",
    "    print(i)\n",
    "    print(row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be153bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column, data = linkedembedded urls from message column\n",
    "\n",
    "def extract_urls(string):\n",
    "    url_pattern = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?Â«Â»ââââ]))\"\n",
    "    url = re.findall(url_pattern, string)      \n",
    "    return str([x[0] for x in url])\n",
    "\n",
    "df['url']  = df['message'].apply(extract_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "df['message'] = df['message'].replace(to_replace = url_pattern, value = r' ', regex = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why is there a url in message column?!\n",
    "df['message'][15814]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c64e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'] = df['url'].astype(str).str[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'] = df['url'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4468dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b929f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentiment information from urls. i.e. web page titles.\n",
    "\n",
    "def extract_web_title(url):\n",
    "    if len(url) > 0:\n",
    "        params = {'headers':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51.0) Gecko/20100101 Firefox/51.0'}\n",
    "        get_url = requests.get(url, headers=params) # Sends a GET request\n",
    "        url_text = get_url.text\n",
    "        return url_text[url_text.find('<title>') + 7 : url_text.find('</title>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c17a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_web_title('https://t.co/yeLvcEFXkC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'] = df['url'].apply([extract_web_title(x) for x in df['url']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_web_title(\"https://t.co/yeLvcEFXkC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd92a53",
   "metadata": {},
   "source": [
    "#### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters\n",
    "\n",
    "def clean_data(tweet):\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    tweet = re.sub(pattern_url, '', tweet) \n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['message'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "\n",
    "def remove_punctuation(tweet):\n",
    "    return ''.join([l for l in tweet if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35204d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the text lower case to remove some noise from capitalisation\n",
    "\n",
    "def remove_cap(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(remove_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4498a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db836419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmetize the words in the dataframe\n",
    "\n",
    "def lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d60048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "\n",
    "#def remove_stop_words(tokens):    \n",
    "#    return [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "#df['clean_tweet'] = df['clean_tweet'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c0429",
   "metadata": {
    "id": "c42c0429"
   },
   "source": [
    "#### Data Cleaning and Formatting Summary\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {
    "id": "81132ab3"
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d38e85",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns, to spot anomalies, to check assumptions with the help of summary statistics and graphical representations.\n",
    "The following section analyses and provides an overview of the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the frequent words\n",
    "#all_words = \" \".join([sentence for sentence in df['clean_tweet']])\n",
    "#df['clean_tweet'] = ''.join(map(str, df['clean_tweet']))\n",
    "#wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(df['clean_tweet'])\n",
    "df\n",
    "# plot the graph\n",
    "#plt.figure(figsize=(15,8))\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ec02f",
   "metadata": {
    "id": "019ec02f"
   },
   "source": [
    "#### Key Insights\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {
    "id": "3fa93ec6"
   },
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a18c4",
   "metadata": {
    "id": "8e1a18c4"
   },
   "source": [
    "Create targets and features dataframes then seperate the test from the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "\n",
    "vector = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words=None, ngram_range=(1, 3)) #max_df=0?\n",
    "X = vector.fit_transform(df['message'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ec9c6",
   "metadata": {
    "id": "691ec9c6"
   },
   "outputs": [],
   "source": [
    "# create targets and features dataset\n",
    "#y =  df['sentiment']\n",
    "#X = df.drop('sentiment', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b0166",
   "metadata": {},
   "source": [
    "X = our features or independant variables (IVs). These will be used to predict our depedant variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fc698",
   "metadata": {},
   "source": [
    "Y = dependant/target variable is also known as the dependent variable (DV) and is the target variable we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7ee66",
   "metadata": {
    "id": "38c7ee66"
   },
   "outputs": [],
   "source": [
    "# split the train data further into train/test data (to perform validation before bringing in the true unseen test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290577f8",
   "metadata": {
    "id": "290577f8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97532c02",
   "metadata": {
    "id": "97532c02"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428d491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {
    "id": "43b2d523"
   },
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba3201",
   "metadata": {},
   "source": [
    "This section takes us through the machine learning process. We train and test a number of regression model algorithms and later select the model with the best performance to be used in this project. From the five modeling techniques, we compare the RMSE values of each model as well as the time taken to train and test each model. This will inform our model selection decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908e867",
   "metadata": {},
   "source": [
    "#### Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb0013",
   "metadata": {
    "id": "b5bb0013"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b29e15",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcc30a",
   "metadata": {
    "id": "e3dcc30a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29a98faa",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab924660",
   "metadata": {
    "id": "ab924660"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39dca57a",
   "metadata": {},
   "source": [
    "#### Model 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd7970",
   "metadata": {
    "id": "6fdd7970"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {
    "id": "6b530251"
   },
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a76a0",
   "metadata": {
    "id": "3d9a76a0",
    "outputId": "1f40a7aa-c07d-45fc-e828-9cabe59c5a32"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a37a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {
    "id": "a8ad0c0d"
   },
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20c699",
   "metadata": {
    "id": "5ff741c2"
   },
   "source": [
    "##### XGBoost Regression\n",
    "\n",
    "This section discusses the inner workings of the best performing model in a simple way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d302f06",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c4d000",
   "metadata": {},
   "source": [
    "Given two datasets, train and test data, we were tasked with following the data science process. \n",
    "\n",
    "We first set out to understand the data and it's space, in other words, we set out to understand the electricity shortfall in Spain, the various variables that may or may not be correlated to the load shortfall in Spain, understanding the reasons behind the correlations or a lack thereof etc. We were presented with a lot of information and our first task was making sure we had a good understanding of the relevant things coming from the data. \n",
    "\n",
    "In our data, we saw null values we had to impute, we encountered unusable data types we needed to transfrom, and data falling in large ranges which we had to scale. All of this formed part of the iterative process of Data Preprocessing, Exploratorty Data Analysis and Data Engineering.\n",
    "\n",
    "Essentially, we set out to understand and transform the data so that we may build an appropriate model that would best predict the load shortfall. \n",
    "\n",
    "We then built a few models then selected the right model out of these models, following an iterative train-validation process. The main model performance metric was the Root Mean Squared Error (RMSE), looking for the model that produced the lowerst RMSE value.\n",
    "\n",
    "At this point, we have addressed the problem statement. In future, when given various cirsumstances (predictor observations) we are now able to predict the corresponding load shortfall with an average error (RMSE) of approximately 4300 (same units as the predicted variable, i.e. load shortfall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d367f0",
   "metadata": {
    "id": "e62dd8a6"
   },
   "source": [
    "#### Kaggle submission file\n",
    "This section creates the Kaggle submission file in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c08265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee3ec9",
   "metadata": {
    "id": "1eee3ec9"
   },
   "outputs": [],
   "source": [
    "x_train_final = df['message']\n",
    "x_test_final = df_test['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c9f91",
   "metadata": {
    "id": "df9c9f91"
   },
   "outputs": [],
   "source": [
    "vector = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words=None, ngram_range=(1, 3)) #max_df=0?\n",
    "x_train_final = vector.fit_transform(df['message'])\n",
    "x_test_final = vector.fit_transform(df_test['message'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bd916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6ebe4",
   "metadata": {
    "id": "5ca6ebe4",
    "outputId": "19325050-d1f0-4425-f485-c1c95006a2d3"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_final, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796b814",
   "metadata": {
    "id": "9796b814"
   },
   "outputs": [],
   "source": [
    "predict_final = model.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7340c1",
   "metadata": {
    "id": "8f7340c1",
    "outputId": "191b918b-383a-4eda-e500-2665969ed8ad"
   },
   "outputs": [],
   "source": [
    "daf = pd.DataFrame(predict_final, columns=['sentiment'])\n",
    "daf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c907861",
   "metadata": {
    "id": "2c907861"
   },
   "outputs": [],
   "source": [
    "df_test_final = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b9f4e",
   "metadata": {
    "id": "767b9f4e"
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"TweetID\":df_test_final['tweetid']})\n",
    "submission = output.join(daf)        \n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c5fd4",
   "metadata": {
    "id": "6f2c5fd4",
    "outputId": "f8f87e65-bec9-4123-baa4-8cda1903f030"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20746d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "KaggleNotebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
